makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
makeVector()
x<-makeVector()
x
cachemean(x)
x$getmean()
x$set(c(0,1,2,3))
x$get()
x$getmean()
cachemean(x)
x$getmean()
cachemean(x)
?solve
solve()
solve
x<-matrix()
x
x<-numeric()
x
x[1]
x[2]
a<-matrix(c(1,2,3,4),nrow=2,ncol=2)
a
solve(a)
View(cachemean)
View(cachemean)
makeCacheMatrix <- function(x = matrix()) {
invX <- NULL
set <- function(y) {
x <<- y
invX <<- solve(x)
}
get <- function() x
setInv <- function(iX) invX <<- iX
getInv <- function() invX
list(set = set, get = get,
setInv = setInv,
getInv = getInv)
}
cacheSolve <- function(x, ...) {
xInv <- x$getInv()
if(!is.null(xInv)) {
message("getting cached data")
return(xInv)
}
data <- x$get()
xInv <- solve(data, ...)
x$setInv(xInv)
xInv
}
a
makeCacheMatrix()
b<-makeCacheMatrix()
b
b$get()
b$setInv()
b$getInv()
x
x
a
b
b$get()
makeCacheMatrix <- function(x = matrix()) {
invX <- NULL
set <- function(y) {
x <<- y
invX <<- NULL
}
get <- function() x
setInv <- function(iX) invX <<- iX
getInv <- function() invX
list(set = set, get = get,
setInv = setInv,
getInv = getInv)
}
b$get()
b<-makeCacheMatrix()
b$get()
b$getInv()
b$set(a)
b$get()
b$getInv()
cacheSolve(b)
cacheSolve(b)
install.packages("swirl")
library(swirl)
rm(list=ls())
library(swirl)
swirl()
d1<-Sys.Date()
class(d1)
unclass(d1)
d1
d2<- as.Date("1969-01-01")
unclass(d2)
t1<-Sys.time()
t1
class(t1)
unclass(t1)
as.POSIXlt(Sys.time())
t2<-as.POSIXlt(Sys.time())
t2
class(t2)
t2
unclass(t2)
str?
str(unclasst2)
str(unclass(t2))
t2$min
weekdays()
weekdays(d1)
months(t1)
quarters(t2)
t3<-"October 17, 1986 08:24"
strptime(t3,"%B %d, %Y %H:%M")
t4<-strptime(t3,"%B %d, %Y %H:%M")
t4
class(t4)
Sys.time()>t1
Sys.time()-t1
difftime(Sys.time(), t1, units = 'days')
head(flags)
dim(flags)
class(flag)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect<-sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors<-flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors,sum)
sapply(flag_colors,mean)
flag_shapes<-flags[,19:23]
lapply(flag_shapes,range)
shape_mat<-sapply(flag_shapes,range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6))
unique_vals<-lapply(flags,unique)
unique_vals
sapply(unique_vals,length)
sapply(unique_vals,unique)
sapply(flags,unique)
lapply(unique_vals,function(elem) elem[2])
sapply(flags,unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags,class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
?table
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
fileUrl<- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
setwd("~/R/datasciencecoursera/Course3")
download.file(fileUrl,"housing06.csv")
houses<-read.csv("housing06.csv")
head(houses$VAL)
houses$VAL==24
sum(houses$VAL==24)
sum(houses$VAL==24,na.rm = TRUE)
library(xls)
install.packages("xlsx")
library(xlsx)
cIdx<-7:15
rIdx<-18:23
datSub<-read.xlsx("NAGP.xlsx",sheetIndex = 1,colIndex = cIdx,rowIndex = rIdx)
datSub<-read.xlsx("NGAP.xlsx",sheetIndex = 1,colIndex = cIdx,rowIndex = rIdx)
datSub
dat<-datSub
sum(dat$Zip*dat$Ext,na.rm=T)
?na.rm
?sum
sum(dat$Zip*dat$Ext,na.rm=T)
install.packages("XML")
library(XML)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileUrl,useInternalNodes = TRUE)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileUrl)
fileUrl
?xmlTreeParse
doc<-xmlTreeParse(fileUrl)
fileUrl<-"http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc<-xmlTreeParse(fileUrl)
doc
class(doc)
rootNode<-xmlRoot(doc)
xmlName(roodnode)
xmlName(roodNode)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
xmlSApply(rootNode,"//zipcode",xmlValue)
xmlSApply(rootNode,"/zipcode",xmlValue)
xmlSApply(rootNode,"//zipcode",xmlValue)
xpathSApply(rootNode,"//zipcode",xmlValue)
rootNode[[1]][[1]]
xpathSApply(rootNode[[1]][[1]],"//zipcode",xmlValue)
traceback()
rm(list=ls())
install.packages("data.table")
library(data.table)
DT<-fread("communities06.csv")
head(DT$pwgtp15)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time()
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time()
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1])
fileUrl<- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
houses<-read.csv("housing06.csv")
sum(houses$VAL==24,na.rm = TRUE)
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
install.packages("sqldf")
a=1
a
a<-1
a
install.packages("httr")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "4d2d6000f17d28265b77",
secret = "4a82e498a30cc2d22c88da0c73b65de6e9b510cf")
myapp
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
install.packages("httpuv")
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "4d2d6000f17d28265b77",
secret = "4a82e498a30cc2d22c88da0c73b65de6e9b510cf")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
?print
print(1)
x=1
print(x)
acs=read.csv("communities06.csb")
acs=read.csv("communities06.csv")
rm(DT)
rm(houses)
class(acs)
library(sqldf)
sqldf("select * from acs where AGEP < 50")
sqldf("select pwgtp1 from acs where AGEP \lt< 50")
sqldf("select pwgtp1 from acs where AGEP < 50")
a=sqldf("select pwgtp1 from acs where AGEP < 50")
head(a)
sqldf("select unique * from acs")
sqldf("select distinct pwgtp1 from acs")
b=sqldf("select distinct pwgtp1 from acs")
c=unique(acs$AGEP)
c
b==4
sum(b==4)
c
sum(b==0)
sum(b==33)
b=sqldf("select distinct AGEP from acs")
con=url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode=readLines(con)
close(con)
htmlCode
htmlCode[10]
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
read.fwf("sst8110.for")
read.fwf("sst8110.for",skip=4)
read.fwf("sst8110.for",skip=4
,
widths=c(12,7,4,9,4,9,4,9,4))
a=read.fwf("sst8110.for",skip=4
,
widths=c(12,7,4,9,4,9,4,9,4))
a
a[1,]
a[,4]
a[4,]
a[4,]
sum(a[4,])
attributes(a)
sum(a[4,])
attributes(a)
a[4,]
a[4,1]
a[4,2]
a[4,2:9]
a[4,1:9]
a[4,2:9]
sum(a[4,2:9])
sum(a[9,2:9])
104+109.8
sum(a[,4])
